{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "from MLWrappers import KerasBlackBox\n",
    "from PrivacyAttacks import MiaPrivacyAttack, LabelOnlyPrivacyAttack, AloaPrivacyAttack\n",
    "from MLPrivacyEvaluator import PrivacyEvaluator\n",
    "\n",
    "warnings.simplefilter(\"ignore\", UserWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = 'nn_keras'\n",
    "DS_NAME = 'adult'\n",
    "DATA_FOLDER = f'./data/{DS_NAME}'\n",
    "\n",
    "# We load the data used to train and test the model, as well as the shadow data\n",
    "train_set = pd.read_csv(f'{DATA_FOLDER}/{DS_NAME}_original_train_set.csv', skipinitialspace=True)\n",
    "train_label = pd.read_csv(f'{DATA_FOLDER}/{DS_NAME}_original_train_label.csv', skipinitialspace=True)\n",
    "test_set = pd.read_csv(f'{DATA_FOLDER}/{DS_NAME}_original_test_set.csv', skipinitialspace=True)\n",
    "shadow_set = pd.read_csv(f'{DATA_FOLDER}/{DS_NAME}_shadow_set.csv', skipinitialspace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we load the target black box model using our wrapper\n",
    "target = KerasBlackBox(f'./models/{DS_NAME}_{MODEL_NAME}.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can define the parameters to be passed to the shadow models (in our case random forests)\n",
    "shadow_forest_params = {'n_estimators': 100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialise the attacks, with the desired parameters for each\n",
    "mia = MiaPrivacyAttack(target,\n",
    "                       n_shadow_models=5,\n",
    "                       shadow_test_size=0.8,\n",
    "                       undersample_attack_dataset=True)\n",
    "label_only = LabelOnlyPrivacyAttack(target,\n",
    "                                    n_shadow_models=5,\n",
    "                                    shadow_model_type='rf',\n",
    "                                    shadow_model_params=shadow_forest_params,\n",
    "                                    n_noise_samples_fit=1000)\n",
    "aloa = AloaPrivacyAttack(target,\n",
    "                         n_shadow_models=5,\n",
    "                         shadow_model_type='rf',\n",
    "                         shadow_model_params=shadow_forest_params,\n",
    "                         n_noise_samples_fit=1000,\n",
    "                         shadow_test_size=0.3,\n",
    "                         undersample_attack_dataset=True)\n",
    "attacks = [\n",
    "    mia,\n",
    "    label_only,\n",
    "    aloa\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We initialise the PrivacyEvaluator object\n",
    "# We pass the target model and the list of attacks we want to use\n",
    "evaluator = PrivacyEvaluator(target, attacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We use the fit() method to execute the attacks, starting from the shadow data\n",
    "evaluator.fit(shadow_set, save_folder = f'./results_{DS_NAME}_{MODEL_NAME}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'mia_attack': {'classification_report': {'IN': {'precision': 0.7995314101625421, 'recall': 0.5655979696483141, 'f1-score': 0.662520855452753, 'support': 19307}, 'OUT': {'precision': 0.1994081710576556, 'recall': 0.4327739796975347, 'f1-score': 0.27301836241259886, 'support': 4827}, 'accuracy': 0.5390320709372669, 'macro avg': {'precision': 0.4994697906100989, 'recall': 0.4991859746729244, 'f1-score': 0.46776960893267594, 'support': 24134}, 'weighted avg': {'precision': 0.6795017890819385, 'recall': 0.5390320709372669, 'f1-score': 0.5846171290126757, 'support': 24134}}}}\n"
     ]
    }
   ],
   "source": [
    "# Then we can obtain the performances using the report() method\n",
    "results = evaluator.report(train_set, test_set)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'IN': {'precision': 0.7995314101625421,\n",
       "  'recall': 0.5655979696483141,\n",
       "  'f1-score': 0.662520855452753,\n",
       "  'support': 19307},\n",
       " 'OUT': {'precision': 0.1994081710576556,\n",
       "  'recall': 0.4327739796975347,\n",
       "  'f1-score': 0.27301836241259886,\n",
       "  'support': 4827},\n",
       " 'accuracy': 0.5390320709372669,\n",
       " 'macro avg': {'precision': 0.4994697906100989,\n",
       "  'recall': 0.4991859746729244,\n",
       "  'f1-score': 0.46776960893267594,\n",
       "  'support': 24134},\n",
       " 'weighted avg': {'precision': 0.6795017890819385,\n",
       "  'recall': 0.5390320709372669,\n",
       "  'f1-score': 0.5846171290126757,\n",
       "  'support': 24134}}"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results['mia_attack']['classification_report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'label_only_attack'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[28], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel_only_attack\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclassification_report\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "\u001b[1;31mKeyError\u001b[0m: 'label_only_attack'"
     ]
    }
   ],
   "source": [
    "results['label_only_attack']['classification_report']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results['aloa_attack']['classification_report']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "evaluator",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
